"""
Test Mistral Connection - Simple Local Test
Prueba la conexiÃ³n desde tu proyecto local al modelo Mistral en Colab
"""

import requests
import json
import time

def test_mistral_simple():
    """Test simple y directo del modelo Mistral"""
    
    # URL del tÃºnel localtunnel
    base_url = "https://mistral-server.loca.lt"
    
    print("ğŸš€ Probando conexiÃ³n local â†’ Colab Mistral")
    print(f"ğŸ”— URL: {base_url}")
    print("=" * 50)
    
    # Headers para bypasear advertencias
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'bypass-tunnel-reminder': 'true',
        'Content-Type': 'application/json'
    }
    
    try:
        # Test 1: Health Check
        print("1ï¸âƒ£ Health Check...")
        response = requests.get(f"{base_url}/health", headers=headers, timeout=10)
        
        if response.status_code == 200:
            health = response.json()
            print(f"âœ… Servidor saludable!")
            print(f"   Modelo cargado: {health.get('model_loaded', False)}")
            print(f"   Timestamp: {health.get('timestamp', 'N/A')}")
        else:
            print(f"âŒ Health check fallÃ³: {response.status_code}")
            return False
        
        # Test 2: GeneraciÃ³n simple en espaÃ±ol
        print("\n2ï¸âƒ£ GeneraciÃ³n en espaÃ±ol...")
        prompt = "Explica quÃ© es un sistema multi-agente en 2 oraciones."
        
        gen_response = requests.post(
            f"{base_url}/generate",
            headers=headers,
            json={
                "prompt": prompt,
                "max_tokens": 50,
                "temperature": 0.7
            },
            timeout=30
        )
        
        if gen_response.status_code == 200:
            result = gen_response.json()
            print("âœ… GeneraciÃ³n exitosa!")
            print(f"ğŸ“ Prompt: {prompt}")
            print(f"ğŸ¤– Respuesta: {result.get('response', 'Sin respuesta')}")
            print(f"ğŸ”¢ Tokens: {result.get('tokens_used', 'N/A')}")
        else:
            print(f"âŒ GeneraciÃ³n fallÃ³: {gen_response.status_code}")
            return False
        
        # Test 3: GeneraciÃ³n tÃ©cnica
        print("\n3ï¸âƒ£ GeneraciÃ³n tÃ©cnica...")
        tech_prompt = "Â¿CuÃ¡les son las ventajas de usar CrewAI para sistemas multi-agente?"
        
        tech_response = requests.post(
            f"{base_url}/generate",
            headers=headers,
            json={
                "prompt": tech_prompt,
                "max_tokens": 80,
                "temperature": 0.5
            },
            timeout=30
        )
        
        if tech_response.status_code == 200:
            result = tech_response.json()
            print("âœ… GeneraciÃ³n tÃ©cnica exitosa!")
            print(f"ğŸ“ Prompt: {tech_prompt}")
            print(f"ğŸ¤– Respuesta: {result.get('response', 'Sin respuesta')}")
        else:
            print(f"âš ï¸ GeneraciÃ³n tÃ©cnica fallÃ³: {tech_response.status_code}")
        
        # Test 4: Info del modelo
        print("\n4ï¸âƒ£ InformaciÃ³n del modelo...")
        info_response = requests.get(f"{base_url}/model_info", headers=headers, timeout=10)
        
        if info_response.status_code == 200:
            info = info_response.json()
            print("âœ… Info del modelo:")
            print(f"   Modelo: {info.get('model_name', 'unknown')}")
            print(f"   Tipo: {info.get('model_type', 'unknown')}")
            print(f"   Device: {info.get('device', 'unknown')}")
        
        print("\n" + "=" * 50)
        print("ğŸ‰ Â¡CONEXIÃ“N EXITOSA!")
        print("âœ… Tu proyecto local puede usar el modelo Mistral en Colab")
        print(f"ğŸ”— URL lista para CrewAI: {base_url}")
        print("ğŸ’¡ Ahora puedes integrar esto en tu sistema multi-agente")
        
        return True
        
    except requests.exceptions.Timeout:
        print("âŒ Timeout - La conexiÃ³n tardÃ³ mucho")
        return False
    except requests.exceptions.ConnectionError:
        print("âŒ Error de conexiÃ³n - Verifica que Colab estÃ© corriendo")
        return False
    except Exception as e:
        print(f"âŒ Error inesperado: {e}")
        return False

def test_crewai_integration():
    """Test especÃ­fico para integraciÃ³n con CrewAI"""
    
    print("\nğŸ”§ Test de integraciÃ³n CrewAI...")
    
    # Importar el cliente local
    try:
        from local_mistral_client import ColabMistralClient
        
        # Crear cliente
        client = ColabMistralClient("dummy_url")  # La URL ya estÃ¡ hardcodeada
        
        # Test del cliente
        print("ğŸ“¡ Probando cliente local...")
        health = client.health_check()
        print(f"âœ… Cliente funciona: {health}")
        
        # Test de generaciÃ³n con el cliente
        print("ğŸ¤– Probando generaciÃ³n con cliente...")
        response = client.generate_text(
            prompt="Â¿QuÃ© es CrewAI?",
            max_tokens=40,
            temperature=0.6
        )
        print(f"âœ… Respuesta del cliente: {response}")
        
        print("ğŸ‰ Cliente local listo para CrewAI!")
        return True
        
    except ImportError:
        print("âš ï¸ No se pudo importar local_mistral_client.py")
        return False
    except Exception as e:
        print(f"âŒ Error en cliente: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ§ª TEST DE CONEXIÃ“N MISTRAL LOCAL â†’ COLAB")
    print("=" * 60)
    
    # Test bÃ¡sico
    success = test_mistral_simple()
    
    if success:
        print("\n" + "="*60)
        # Test de integraciÃ³n
        test_crewai_integration()
    
    print("\n" + "="*60)
    print("ğŸ Tests completados!")
    
    if success:
        print("âœ… Â¡Todo listo para trabajar con CrewAI!")
    else:
        print("âŒ Hay problemas de conexiÃ³n que resolver") 